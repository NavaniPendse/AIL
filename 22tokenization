import re
import nltk
from nltk.corpus import stopwords
from spellchecker import SpellChecker

nltk.download('punkt')
nltk.download('stopwords')

# Step 1: Read file
with open('sample_text.txt', 'r') as file:
    text = file.read()

# Step 2: Clean text
text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special chars
text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces

# Step 3: Lowercase
text = text.lower()

# Step 4: Tokenization
tokens = nltk.word_tokenize(text)

# Step 5: Remove stopwords
filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]

# Step 6: Spell Correction
spell = SpellChecker()
corrected_tokens = [spell.correction(word) for word in filtered_tokens]

print(corrected_tokens)
